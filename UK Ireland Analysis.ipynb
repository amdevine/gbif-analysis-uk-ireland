{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23 October 2018\n",
    "\n",
    "# UK Gap Analysis\n",
    "\n",
    "This notebook contains a gap analysis of GBIF Specimens from the United Kingdom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import the required Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import reverse_geocoder as rg\n",
    "from pandas.api.types import CategoricalDtype\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download GBIF dataset\n",
    "\n",
    "From the GBIF Occurrence Search page (https://www.gbif.org/occurrence/search), search for all records where:  \n",
    "`Basis of record = Preserved specimen, Material sample`  \n",
    "`Country = United Kingdom`  \n",
    "\n",
    "Download the dataset. Dataset citation: \n",
    "> GBIF.org (22 October 2018) GBIF Occurrence Download https://doi.org/10.15468/dl.pdpekf\n",
    "\n",
    "File saved as **gbif_uk_specimens_20181022.csv**  \n",
    "1,365,100 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbif_file = 'gbif_uk_specimens_20181022.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract distinct families (+ higher taxa) with valid lat-long coordinates\n",
    "\n",
    "Import GBIF CSV file (specified above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbif_all = pd.read_csv(gbif_file, sep=\"\\t\", dtype='str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From data, select distinct `kingdom`, `phylum`, `class`, `order`, `family`, `decimalLatitude`, `decimalLongitude`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs = gbif_all[['kingdom', 'phylum', 'class', 'order', 'family', 'decimalLatitude', 'decimalLongitude']].copy()\n",
    "recs = recs.fillna('')\n",
    "recs = recs.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the data; select only records with numeric lat/long values, and remove records with no taxonomic information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numericcoords(x):\n",
    "    for coord in [x['decimalLatitude'], x['decimalLongitude']]:\n",
    "        if coord == '':\n",
    "            return False\n",
    "        try:\n",
    "            pd.to_numeric(coord)\n",
    "        except ValueError:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "recs['valid'] = recs.apply(lambda x: numericcoords(x), axis=1)\n",
    "recs = recs[recs.valid == True]\n",
    "recs = recs.loc[:, 'kingdom':'decimalLongitude']\n",
    "\n",
    "blanktaxa = (recs['kingdom'] == '') & \\\n",
    "    (recs['phylum'] == '') & \\\n",
    "    (recs['class'] == '') & \\\n",
    "    (recs['order'] == '') & \\\n",
    "    (recs['family'] == '')\n",
    "recs = recs[~blanktaxa]\n",
    "print('{} records with valid coordinates found'.format(recs.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the filtered data file so that it can be added to Dropbox. (The original GBIF file is too huge!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs_file = 'gbif_uk_families.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs.to_csv(recs_file, index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Geocode records and filter out non-UK records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Re-)import the GBIF records from the file exported in the last step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs = pd.read_csv(recs_file, sep='\\t', dtype='str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert string columns `decimalLatitude` and `decimalLongitude` to numeric columns `latitude` and `longitude` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs['decimalLatitude'] = pd.to_numeric(recs['decimalLatitude'])\n",
    "recs['decimalLongitude'] = pd.to_numeric(recs['decimalLongitude'])\n",
    "recs = recs.rename(columns={'decimalLatitude': 'latitude', 'decimalLongitude': 'longitude'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rough plot of `latitude` and `longitude`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotdata = {'latitude': recs.latitude, 'longitude': recs.longitude}\n",
    "coordmap = pd.DataFrame(data=plotdata)\n",
    "coordmap.plot.scatter(x='longitude', y='latitude');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although these samples are supposed to be from the United Kingdom only, coordinates are present all around the globe. Highest concentrations seem to be in Western Europe, Australia, and the Southern Atlantic/Antarctica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a. reverse_geocoder\n",
    "\n",
    "GeoNames.org is a website that provides reverse-geocoding of lat/long coordinates to country names, etc. There is a Python library, `reverse_geocoder` (imported as `rg`), that allows users to query the GeoNames database without making API calls.\n",
    "\n",
    "*(Note, the latitude and longitude returned from rg are not the same as the ones supplied. reverse_geocoder finds the nearest city to the coordinates supplied, then provides the coordinates of that city. Don't use the returned lat/lon as the ones provided.)*\n",
    "\n",
    "reverse_geocoder requires a (latitude, longitude) tuple to geocode. Added a column, `coordinate`, containing this tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs['coordinate'] = recs.apply(lambda row: (row['latitude'], row['longitude']), axis=1)\n",
    "recs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For efficiency, isolate a list of unique coordinates (`ucoords`) to be reverse geocoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://gist.github.com/bsweger/e5817488d161f37dcbd2\n",
    "ucoords = pd.unique(recs.coordinate.ravel()).tolist()\n",
    "print(len(ucoords), \"unique coordinates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reverse geocode the list of ucoords to obtain the country code, administrative district 1, and administrative district 2. Then add the ucoord back to the result. Create a DataFrame, `geolocs`, from the rg results. For ease of joining in the next step, the ucoord is set as the index for this df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = rg.search(ucoords)\n",
    "gl = []\n",
    "\n",
    "for r in results:\n",
    "    x = {}\n",
    "    x['cc'] = r['cc']\n",
    "    x['admin1'] = r['admin1']\n",
    "    gl.append(x)\n",
    "\n",
    "for x in range(len(gl)):\n",
    "    gl[x]['lat_lon'] = ucoords[x]\n",
    "      \n",
    "geolocs = pd.DataFrame.from_records(gl, columns = ['lat_lon', 'cc', 'admin1'], index='lat_lon')\n",
    "geolocs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 4b. Join geolocs to recs to obtain country code and admin1 for each taxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "georecs = recs.join(\n",
    "    geolocs, \n",
    "    on = 'coordinate', \n",
    "    how = 'left'\n",
    ")\n",
    "georecs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter records to just those from Great Britain (GB; includes England, Northern Ireland, Scotland, and Wales) and Ireland (IE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk = georecs[(georecs['cc'] == 'GB') | (georecs['cc'] == 'IE')].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the `admin1` areas found in Ireland."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_admin1 = sorted(list(georecs[georecs['cc'] == 'GB'].admin1.unique()))\n",
    "ie_admin1 = sorted(list(georecs[georecs['cc'] == 'IE'].admin1.unique()))\n",
    "print('GB admin1 areas: {}'.format(gb_admin1))\n",
    "print('IE admin1 areas: {}'.format(ie_admin1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4c. Assign `country` value to each record\n",
    "\n",
    "For records from Great Britain, the admin1 area is the actual country name (England, Northern Ireland, Scotland, Wales). For records from Ireland, the admin1 area is the county (Connacht, Leinster, Munster, Ulster). I would like to create a map at the country level, so I am going to add a column `country` that translates records to one of five countries: England, Northern Ireland, Scotland, Wales, and Ireland."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assigncountry(admin1):\n",
    "    if admin1 in gb_admin1:\n",
    "        return admin1\n",
    "    elif admin1 in ie_admin1:\n",
    "        return 'Ireland'\n",
    "    \n",
    "\n",
    "uk['country'] = uk['admin1'].apply(assigncountry)\n",
    "uk.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up DataFrame - remove redundant `coordinate` column, move `country`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk = uk[['kingdom', 'phylum', 'class', 'order', 'family', \n",
    "         'country', 'latitude', 'longitude', 'cc', 'admin1']]\n",
    "uk.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save geocoded data to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_taxa_file = 'uk_taxa_geos.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk.to_csv(uk_taxa_file, sep = '\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5. Counts of KPCOFG in each country\n",
    "\n",
    "Re-import country data from CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk = pd.read_csv(uk_taxa_file, sep='\\t', dtype='str')\n",
    "uk['latitude'] = pd.to_numeric(uk['latitude'])\n",
    "uk['longitude'] = pd.to_numeric(uk['longitude'])\n",
    "uk.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate total counts of KPCOF in UK/Ireland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_total = uk[['kingdom', 'phylum', 'class', 'order', 'family']].agg(pd.Series.nunique)\n",
    "counts_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate total counts of KPCOF by country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_country = uk[['country', 'kingdom', 'phylum', 'class', 'order', 'family']] \\\n",
    "                   .groupby('country') \\\n",
    "                   .agg(pd.Series.nunique)\n",
    "counts_country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. GGBN\n",
    "\n",
    "For each of the countries, we want an idea of how many of their KPCOF are currently in GGBN versus not. \n",
    "\n",
    "GGBN data are available through the GGBN Data Portal API. A Gist on querying the API is available here: https://gist.github.com/amdevine/b21ca15fcfaac5c1e75fc33fdcde4056. I use a Python script to retrieve the data and save it as a text file.\n",
    "\n",
    "Import latest GGBN download file, cleaned and standardized to the CoL backbone taxonomy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggbn_file = 'GGBN Download 2018-10-01.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ggbn_all = pd.read_csv(ggbn_file, sep='\\t', dtype='str').fillna('xxxxxxxxxxxxxx')\n",
    "ggbn = ggbn_all.loc[:, 'kingdom':'family'] \\\n",
    "               .drop_duplicates() \\\n",
    "               .sort_values(['kingdom', 'phylum', 'class', 'order', 'family'])\n",
    "ggbn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a second table containing whether the KPCOF are in GGBN (`True`) or not (`False`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inggbn = uk.loc[:, 'kingdom':'country']\n",
    "inggbn['k'] = uk['kingdom'].isin(ggbn.kingdom)\n",
    "inggbn['p'] = uk['phylum'].isin(ggbn.phylum)\n",
    "inggbn['c'] = uk['class'].isin(ggbn['class'])\n",
    "inggbn['o'] = uk['order'].isin(ggbn['order'])\n",
    "inggbn['f'] = uk['family'].isin(ggbn.family)\n",
    "inggbn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculated the total number of families in the UK/Ireland that are in GGBN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ggbn_families = inggbn[['family', 'f']].drop_duplicates()\n",
    "total_ggbn_families = sum(total_ggbn_families.f)\n",
    "print('There are {} families in UK/Ireland that are in GGBN.'.format(total_ggbn_families))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create summary table with counts of KPCOF in GGBN for each country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kingdoms = inggbn[['country', 'kingdom', 'k']].drop_duplicates()\n",
    "kingdoms = kingdoms[['country', 'k']].groupby('country').agg(sum)\n",
    "phyla = inggbn[['country', 'phylum', 'p']].drop_duplicates()\n",
    "phyla = phyla[['country', 'p']].groupby('country').agg(sum)\n",
    "classes = inggbn[['country', 'class', 'c']].drop_duplicates()\n",
    "classes = classes[['country', 'c']].groupby('country').agg(sum)\n",
    "orders = inggbn[['country', 'order', 'o']].drop_duplicates()\n",
    "orders = orders[['country', 'o']].groupby('country').agg(sum)\n",
    "families = inggbn[['country', 'family', 'f']].drop_duplicates()\n",
    "families = families[['country', 'f']].groupby('country').agg(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "in_ggbn = pd.merge(kingdoms, phyla, on='country')\n",
    "in_ggbn = pd.merge(in_ggbn, classes, on='country')\n",
    "in_ggbn = pd.merge(in_ggbn, orders, on='country')\n",
    "in_ggbn = pd.merge(in_ggbn, families, on='country')\n",
    "in_ggbn.columns = ['kingdom', 'phylum', 'class', 'order', 'family']\n",
    "in_ggbn = pd.DataFrame(in_ggbn.to_records())\n",
    "in_ggbn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Un-pivot\" the GGBN data into one column, to be added to results later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "in_ggbn = pd.melt(in_ggbn, \n",
    "                  id_vars=['country'], \n",
    "                  value_vars=['kingdom', 'phylum', 'class', 'order', 'family'],\n",
    "                  var_name='taxrank',\n",
    "                  value_name='countggbn',\n",
    "                 ).drop_duplicates()\n",
    "cattype = CategoricalDtype(categories=['kingdom', 'phylum', 'class', 'order', 'family'], ordered=True)\n",
    "in_ggbn['taxrank'] = in_ggbn['taxrank'].astype(cattype)\n",
    "in_ggbn['countggbn'] = in_ggbn['countggbn'].astype('int32', copy=False)\n",
    "in_ggbn = in_ggbn.sort_values(['country', 'taxrank'])\n",
    "in_ggbn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Catalogue of Life\n",
    "\n",
    "We also want to look at the percent of life on Earth available in the UK and Ireland. For our backbone taxonomy, we are using the **Catalogue of Life, 24 September 2018** download available from the Darwin Core Archive Export (http://www.catalogueoflife.org/DCA_Export/archive.php) repository.\n",
    "\n",
    "After light processing of this download, we are left with a file, **CoL Genera 2018-09-24.tsv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_file = 'CoL Genera 2018-09-24.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_all = pd.read_csv(col_file, sep='\\t', dtype='str').fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = col_all.loc[:, 'kingdom':'family'] \\\n",
    "             .drop_duplicates() \\\n",
    "             .sort_values(['kingdom', 'phylum', 'class', 'order', 'family'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Found the number of unique names for each taxonomic rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "col_counts = col.agg(pd.Series.nunique)\n",
    "col_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Percentages of CoL taxa in each country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Unpivot\" the `uk` table. Leave country as a grouping variable, but gather all the taxonomic name columns into two columns: one column contains the taxonomic rank (`taxrank`), the other contains the taxonomic name (`taxname`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxcountries = pd.melt(uk, \n",
    "                       id_vars=['country'], \n",
    "                       value_vars=['kingdom', 'phylum', 'class', 'order', 'family'],\n",
    "                       var_name='taxrank',\n",
    "                       value_name='taxname',\n",
    "                      ).drop_duplicates()\n",
    "cattype = CategoricalDtype(categories=['kingdom', 'phylum', 'class', 'order', 'family'], ordered=True)\n",
    "taxcountries['taxrank'] = taxcountries['taxrank'].astype(cattype)\n",
    "taxcountries.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate the unpivoted data by country name and taxonomic rank, counting the unique elements for each country and taxrank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tax_counts = taxcountries.groupby(['country', 'taxrank']).agg(pd.Series.nunique)\n",
    "tax_counts = pd.DataFrame(tax_counts.to_records())\n",
    "tax_counts = tax_counts.rename(columns={'taxname': 'ukcount'})\n",
    "tax_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the total taxrank counts found for the Catalogue of Life (`col_counts`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tax_counts['colcount'] = tax_counts['taxrank'].apply(lambda x: col_counts[x])\n",
    "tax_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a column containing the percent of all CoL families found in that country and at that taxonomic rank in the UK and Ireland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tax_counts = tax_counts.assign(ukpercent=tax_counts.ukcount/tax_counts.colcount)\n",
    "tax_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create columns containing the counts and percents of taxa in GGBN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tax_counts = pd.merge(tax_counts, in_ggbn, on=['country', 'taxrank'])\n",
    "tax_counts = tax_counts.assign(percent_not_ggbn=(tax_counts.ukcount-tax_counts.countggbn)/tax_counts.ukcount)\n",
    "tax_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export table with counts to TSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_file = 'uk_taxa_counts.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tax_counts.to_csv(counts_file, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Produced a map of UK/Ireland in Inkscape.\n",
    "\n",
    "![](uk_ireland_map_small.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
